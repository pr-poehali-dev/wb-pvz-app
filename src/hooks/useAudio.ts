import { useCallback, useRef, useState } from 'react';

export const useAudio = () => {
  const audioRef = useRef<HTMLAudioElement>(null);
  const [isSpeaking, setIsSpeaking] = useState(false);

  // Web Speech API –¥–ª—è –æ–∑–≤—É—á–∫–∏
  const speak = useCallback((text: string, priority = false) => {
    if ('speechSynthesis' in window) {
      // –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ç–µ–∫—É—â—É—é –æ–∑–≤—É—á–∫—É –µ—Å–ª–∏ —ç—Ç–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
      if (priority) {
        window.speechSynthesis.cancel();
      }
      
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.lang = 'ru-RU';
      utterance.rate = 1.1;
      utterance.pitch = 1.0;
      utterance.volume = 0.8;
      
      utterance.onstart = () => setIsSpeaking(true);
      utterance.onend = () => setIsSpeaking(false);
      utterance.onerror = () => {
        setIsSpeaking(false);
        console.log('–û—à–∏–±–∫–∞ –æ–∑–≤—É—á–∫–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º console.log:', text);
      };
      
      window.speechSynthesis.speak(utterance);
    } else {
      console.log('–û–ó–í–£–ß–ö–ê:', text);
      // –í–∏–∑—É–∞–ª—å–Ω–∞—è –æ–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å
      const toast = document.createElement('div');
      toast.textContent = `üîä ${text}`;
      toast.className = 'fixed top-4 right-4 bg-primary text-white px-4 py-2 rounded-lg shadow-lg z-50 animate-fade-in';
      document.body.appendChild(toast);
      setTimeout(() => {
        document.body.removeChild(toast);
      }, 3000);
    }
  }, []);

  // –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤
  const playAudioFile = useCallback(async (audioType: 'cell' | 'discount' | 'camera' | 'rate', cellNumber?: number) => {
    try {
      // –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª—É
      let audioPath = '';
      let fallbackText = '';
      
      switch (audioType) {
        case 'cell':
          audioPath = `/audio/cells/${cellNumber || 1}.mp3`;
          fallbackText = `–Ø—á–µ–π–∫–∞ –Ω–æ–º–µ—Ä ${cellNumber || 1}`;
          break;
        case 'discount':
          audioPath = '/audio/discount.mp3';
          fallbackText = '–¢–æ–≤–∞—Ä—ã —Å–æ —Å–∫–∏–¥–∫–æ–π! –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –í–ë –∫–æ—à–µ–ª—ë–∫!';
          break;
        case 'camera':
          audioPath = '/audio/camera.mp3';
          fallbackText = '–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ç–æ–≤–∞—Ä –ø–æ–¥ –∫–∞–º–µ—Ä–æ–π!';
          break;
        case 'rate':
          audioPath = '/audio/rate.mp3';
          fallbackText = '–û—Ü–µ–Ω–∏—Ç–µ –Ω–∞—à –ø—É–Ω–∫—Ç –≤—ã–¥–∞—á–∏ –≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏ –í–ë!';
          break;
      }

      // –ü–æ–ø—ã—Ç–∫–∞ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ—Å—Ç–∏ –∞—É–¥–∏–æ—Ñ–∞–π–ª
      if (audioRef.current) {
        audioRef.current.src = audioPath;
        audioRef.current.oncanplaythrough = () => {
          if (audioRef.current) {
            setIsSpeaking(true);
            audioRef.current.play().catch(() => {
              // –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ—Å—Ç–∏ —Ñ–∞–π–ª, –∏—Å–ø–æ–ª—å–∑—É–µ–º Web Speech API
              setIsSpeaking(false);
              speak(fallbackText, true);
            });
          }
        };
        audioRef.current.onended = () => setIsSpeaking(false);
        audioRef.current.onerror = () => {
          // –ï—Å–ª–∏ –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º Web Speech API
          setIsSpeaking(false);
          speak(fallbackText, true);
        };
        audioRef.current.load();
      } else {
        // –ï—Å–ª–∏ –Ω–µ—Ç ref, –∏—Å–ø–æ–ª—å–∑—É–µ–º Web Speech API
        speak(fallbackText, true);
      }
    } catch (error) {
      // –í —Å–ª—É—á–∞–µ –ª—é–±–æ–π –æ—à–∏–±–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º Web Speech API
      console.error('–û—à–∏–±–∫–∞ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è –∞—É–¥–∏–æ:', error);
      speak(fallbackText, true);
    }
  }, [speak]);

  return {
    audioRef,
    isSpeaking,
    speak,
    playAudioFile
  };
};